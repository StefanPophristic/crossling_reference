}
rm(chat_temp, guesserChat, directorChat, i, sel, images)
d <- cbind(d, directorAllMessages, directorFirstMessage, guesserAllMessages, nameClickedObj)
rm(directorAllMessages, directorFirstMessage, guesserAllMessages, nameClickedObj)
d <- d %>%
mutate(correct = ifelse(d$target$id == listenerSelection, 1, 0))
sprintf('Number of games excluded due to native lang: %d', length(excludeEnglish))
sprintf('Number of games after exclusions: %d', length(unique(d$gameId)) - length(excludeEnglish))
roundsPerGame <- d %>% group_by(gameId) %>% summarise(n = n())
sprintf('Avg. of rounds per game (should be exactly 72): %f', mean(roundsPerGame$n))
print("Rounds per game:")
roundsPerGame
excludeIncomplete <- (roundsPerGame %>% filter(n < 72))$gameId
# we can exclude incomplete games if we want... but Degen et al. 2020 do not.
d <- d %>%
# filter(!(gameId %in% excludeIncomplete))
filter()
sprintf('Incomplete games: %d', length(excludeIncomplete))
head(d %>% mutate(targetName = d$target$name) %>%
select(condition, targetName, directorFirstMessage, nameClickedObj))
toplot =  d %>%
group_by(gameId) %>%
summarise(Mean=mean(correct),CILow=ci.low(correct),CIHigh=ci.high(correct)) %>%
ungroup() %>%
mutate(YMin=Mean-CILow,YMax=Mean+CIHigh) %>%
mutate(lowacc=ifelse(Mean<0.70,"1","0"))
h=0.70
ggplot(toplot, aes(x=reorder(gameId,Mean), y=Mean)) +
geom_bar(stat="identity", fill="lightblue") +
geom_hline(yintercept=h) +
geom_text(aes(0, h, label=h, vjust=-1, hjust=-0.3)) +
geom_errorbar(aes(ymin = YMin, ymax = YMax),width=.25) +
theme(axis.text.x=element_blank()) +
ylab("Accuracy") +
xlab("English speakers")
ggsave(file="viz/accuracy.pdf",width=5,height=3)
excludeAccuracy = toplot %>%
filter(lowacc==1)
excludeAccuracy
d = d[!(d$gameId %in% excludeAccuracy$gameId),]
sprintf("Games remaining after exclusion: %d", length(unique(d$gameId))) #46 games left
toplot =  d %>%
group_by(condition) %>%
summarise(Mean=mean(correct),CILow=ci.low(correct),CIHigh=ci.high(correct)) %>%
ungroup() %>%
mutate(YMin=Mean-CILow,YMax=Mean+CIHigh) %>%
mutate(lowacc=ifelse(Mean<0.70,"1","0"))
ggplot(toplot, aes(x=reorder(condition,Mean), y=Mean, fill = condition)) +
geom_bar(position="dodge", stat="identity") +
geom_errorbar(aes(ymin = YMin, ymax = YMax),width=.25, position=position_dodge(width = 0.9)) +
theme(axis.text.x = element_text(angle=90),
legend.position = "none") +
ylab("Accuracy") +
xlab("Trial type")
ggsave(file="viz/accuracy_trialType.pdf",width=6,height=4.5)
# Was a color mentioned?
d$colorMentioned = ifelse(grepl("gray|grey|green|purple|white|black|brown|violet|yellow|gold|orange|silver|blue|pink|red", d$directorFirstMessage, ignore.case = TRUE), T, F)
table(d$colorMentioned)
# Was a size mentioned?
d$sizeMentioned = ifelse(grepl("big|small|bigger|smaller|tiny|huge|large|larger|little|biggest|smallest|largest", d$directorFirstMessage, ignore.case = TRUE), T, F)
table(d$sizeMentioned)
# Was the object's type (noun) mentioned?
d$typeMentioned = ifelse(grepl("avocado|balloon|cap|belt|bike|billiardball|binder|book|bracelet|bucket|butterfly|candle|chair|coat hanger|comb|cushion|guitar|flower|frame|golf ball|hair dryer|jacket|napkin|ornament|pepper|phone|rock|rug|shoe|stapler|tack|teacup|toothbrush|turtle|wedding cake|yarn", d$directorFirstMessage, ignore.case = TRUE), T, F)
table(d$typeMentioned)
# Was a bleached noun used?
d$oneMentioned = ifelse(grepl(" one|thing|item|object", d$directorFirstMessage, ignore.case = TRUE), T, F)
table(d$oneMentioned)
# Was an article used?
d$theMentioned = ifelse(grepl("the |a |an ", d$directorFirstMessage, ignore.case = TRUE), T, F)
table(d$theMentioned)
# Write this dataset for manual correction of typos like "pruple"
write_delim(data.frame(d %>%
select(-target, -images, -listenerImages, -speakerImages,
-chatLog, -gameChat)),
"../../data/englishPilot/preManualTypoCorrection.tsv", delim="\t")
# Read manually corrected dataset for further preprocessing
d = read_delim("../../data/englishPilot/preManualTypoCorrection.tsv", delim = "\t") %>%
filter(grepl("color|size", condition)) %>%
mutate(clickedFeatures = strsplit(nameClickedObj, "_"),
clickedColor = map(clickedFeatures, pluck, 2),
clickedSize = map(clickedFeatures, pluck, 1),
clickedType = map(clickedFeatures, pluck, 3))
View(d)
contrasts(centered$SufficientProperty)
colsizerows = nrow(d)
# How many trials were automatically labelled as mentioning a pre-coded level of reference?
auto_trials = sum(d$automaticallyLabelledTrial)
print(paste("percentage of automatically labelled trials: ", auto_trials*100/colsizerows)) # 95.7 in Degen 2020
# How many trials were manually labelled as mentioning a pre-coded level of reference? (overlooked by grep search due to typos or grammatical modification of the expression)
manu_trials = sum(d$manuallyAddedTrials)
print(paste("percentage of manually added trials: ", manu_trials*100/colsizerows)) # 1.9 in Degen 2020
# How often were articles omitted?
no_article_trials = colsizerows - sum(d$theMentioned)
print(paste("percentage trials where articles were omitted: ", no_article_trials*100/colsizerows)) # 71.6 in Degen 2020
# How often were nouns omitted?
d$article_mentioned = ifelse(d$oneMentioned == TRUE | d$theMentioned == TRUE, 1, 0)
no_noun_trials = colsizerows - sum(d$article_mentioned)
print(paste("percentage of trials where nouns were omitted: ", no_noun_trials*100/colsizerows)) # 88.6 in Degen 2020
# In how many cases did the listener choose the wrong object?
print(paste(100*(1-(sum(d$correct)/colsizerows)),"% of cases of non-target choices")) # 1.5 in Degen 202
# How many unique pairs?
length(unique(d$gameId)) # 64
# Code for each trial: sufficient property, number of total distractors, number of distractors that differ on and that share insufficient dimension value with target
d$SufficientProperty = as.factor(ifelse(d$condition %in% c("size21", "size22", "size31", "size32", "size33", "size41", "size42", "size43", "size44"), "size", "color"))
d$RedundantProperty = ifelse(d$SufficientProperty == 'color',"size redundant","color redundant")
d$NumDistractors = ifelse(d$condition %in% c("size21","size22","color21","color22"), 2, ifelse(d$condition %in% c("size31","size32","size33","color31","color32","color33"),3,4))
d$NumDiffDistractors = ifelse(d$condition %in% c("size22","color22","size33","color33","size44","color44"), 0, ifelse(d$condition %in% c("size21","color21","size32","color32","size43","color43"), 1, ifelse(d$condition %in% c("size31","color31","size42","color42"),2,ifelse(d$condition %in% c("size41","color41"),3, 4))))
d$NumSameDistractors = ifelse(d$condition %in% c("size21","size31","size41","color21","color31","color41"), 1, ifelse(d$condition %in% c("size22","size32","size42","color22","color32","color42"), 2, ifelse(d$condition %in% c("size33","color33","size43","color43"),3,ifelse(d$condition %in% c("size44","color44"),4,NA))))
d$SceneVariation = d$NumDiffDistractors/d$NumDistractors
d$TypeMentioned = d$typeMentioned
# Add empirical typicality ratings
# Add color typicality ratings ("how typical is this color for a stapler?" wording)
typicalities = read.table("../../data/Degen2020_Typicality/typicality_exp1_colortypicality.csv",header=T)
head(typicalities)
typicalities = typicalities %>%
group_by(Item) %>%
mutate(OtherTypicality = c(Typicality[2],Typicality[1]),OtherColor = c(as.character(Color[2]),as.character(Color[1])))
typicalities = as.data.frame(typicalities)
row.names(typicalities) = paste(typicalities$Item,typicalities$Color)
d$ColorTypicality = typicalities[paste(d$clickedType,d$clickedColor),]$Typicality
d$OtherColorTypicality = typicalities[paste(d$clickedType,d$clickedColor),]$OtherTypicality
d$OtherColor = typicalities[paste(d$clickedType,d$clickedColor),]$OtherColor
d$TypicalityDiff = d$ColorTypicality-d$OtherColorTypicality
d$normTypicality = d$ColorTypicality/(d$ColorTypicality+d$OtherColorTypicality)
# Add typicality norms for objects with modified and unmodified utterances ("how typical is this for a stapler?" vs "how typical is this for a red stapler?" wording)
typs = read.table("../../data/Degen2020_Typicality/typicality_exp1_objecttypicality.csv",header=T)
head(typs)
typs = typs %>%
group_by(Item) %>%
mutate(OtherTypicality = c(Typicality[3],Typicality[4],Typicality[1],Typicality[2]))
typs = as.data.frame(typs)
row.names(typs) = paste(typs$Item,typs$Color,typs$Modification)
d$ColorTypicalityModified = typs[paste(d$clickedType,d$clickedColor,"modified"),]$Typicality
d$OtherColorTypicalityModified = typs[paste(d$clickedType,d$clickedColor,"modified"),]$OtherTypicality
d$TypicalityDiffModified = d$ColorTypicalityModified-d$OtherColorTypicalityModified
d$normTypicalityModified = d$ColorTypicalityModified/(d$ColorTypicalityModified+d$OtherColorTypicalityModified)
d$ColorTypicalityUnModified = typs[paste(d$clickedType,d$clickedColor,"unmodified"),]$Typicality
d$OtherColorTypicalityUnModified = typs[paste(d$clickedType,d$clickedColor,"unmodified"),]$OtherTypicality
d$TypicalityDiffUnModified = d$ColorTypicalityUnModified-d$OtherColorTypicalityUnModified
d$normTypicalityUnModified = d$ColorTypicalityUnModified/(d$ColorTypicalityUnModified+d$OtherColorTypicalityUnModified)
# Exclude trials on which target wasn't selected
targets = d %>% filter(correct == 1)
nrow(targets) # 2138 cases in Degen 2020
# Categorize everything that isn't a size, color, or size-and-color mention as OTHER
targets$UtteranceType = as.factor(ifelse(targets$sizeMentioned & targets$colorMentioned, "size and color", ifelse(targets$sizeMentioned, "size", ifelse(targets$colorMentioned, "color","OTHER"))))
# examples of what people say when utterance is not clearly categorizable:
targets[targets$UtteranceType == "OTHER",]$directorFirstMessage
targets = droplevels(targets)
table(targets$UtteranceType)
table(targets[targets$UtteranceType == "OTHER",]$gameId)
targets$Color = ifelse(targets$UtteranceType == "color",1,0)
targets$Size = ifelse(targets$UtteranceType == "size",1,0)
targets$SizeAndColor = ifelse(targets$UtteranceType == "size and color",1,0)
targets$Other = ifelse(targets$UtteranceType == "OTHER",1,0)
targets$Item = sapply(strsplit(as.character(targets$nameClickedObj),"_"), "[", 3)
targets$redUtterance = as.factor(ifelse(targets$UtteranceType == "size and color","redundant",ifelse(targets$UtteranceType == "size" & targets$SufficientProperty == "size", "minimal", ifelse(targets$UtteranceType == "color" & targets$SufficientProperty == "color", "minimal", "other"))))
targets$RatioOfDiffToSame = targets$NumDiffDistractors/targets$NumSameDistractors
targets$DiffMinusSame = targets$NumDiffDistractors-targets$NumSameDistractors
# Prepare data for Bayesian Data Analysis by collapsing across specific size and color terms
targets$redUtterance = as.factor(as.character(targets$redUtterance))
targets$CorrectProperty = ifelse(targets$SufficientProperty == "color" & (targets$Color == 1 | targets$SizeAndColor == 1), 1, ifelse(targets$SufficientProperty == "size" & (targets$Size == 1 | targets$SizeAndColor == 1), 1, 0)) # 20 cases of incorrect property mention
targets$minimal = ifelse(targets$SizeAndColor == 0 & targets$UtteranceType != "OTHER", 1, 0)
targets$redundant = ifelse(targets$SizeAndColor == 1, 1, 0)
targets$BDAUtterance = "size"#as.character(targets$clickedSize)
targets[targets$Color == 1,]$BDAUtterance = as.character(targets[targets$Color == 1,]$clickedColor)
targets[targets$SizeAndColor == 1,]$BDAUtterance = paste("size",targets[targets$SizeAndColor == 1,]$clickedColor,sep="_")
targets$redBDAUtterance = "size_color"
targets[targets$Color == 1,]$redBDAUtterance = "color"
targets[targets$Size == 1,]$redBDAUtterance = "size"
targets[targets$Other == 1,]$redBDAUtterance = "other"
targets$BDASize = "size"
targets$BDAColor = "color"
targets$BDAFullColor = targets$clickedColor
targets$BDAOtherColor = "othercolor"
targets$BDAItem = "item"
# Code non-sensical and "closest"/"Farthest" cases (BW: not sure what this is supposed to do)
targets[targets$redBDAUtterance != "other" & targets$CorrectProperty == 0,c("gameId","condition","nameClickedObj","directorFirstMessage")]
targets$WeirdCases = FALSE
targets[targets$redBDAUtterance != "other" & targets$CorrectProperty == 0  & !targets$gameId %in% c(),]$WeirdCases = TRUE
# Write Bayesian data analysis files (data and unique conditions)
write.csv(targets[targets$redBDAUtterance != "other" & targets$WeirdCases == FALSE,c("gameId","roundNumber","condition","BDASize","BDAColor","BDAOtherColor","BDAItem","redBDAUtterance")],file="../../data/englishPilot/bda_data.csv",quote=F,row.names=F)
write.csv(unique(targets[targets$redBDAUtterance != "other" & targets$WeirdCases == FALSE,c("BDAColor","BDASize","condition","BDAOtherColor","BDAItem")]),file="../../data/englishPilot/unique_conditions.csv",quote=F,row.names=F)
dd = targets %>%
filter(redUtterance != "other" & WeirdCases == FALSE) %>%
rename(Trial=roundNumber, TargetItem=nameClickedObj, gameid = gameId,
refExp = directorFirstMessage, speakerMessages = directorAllMessages,
listenerMessages = guesserAllMessages) %>%
mutate(clickedColor = as.character(clickedColor),
clickedSize = as.character(clickedSize),
clickedType = as.character(clickedType)) %>%
select(gameid,Trial,TargetItem,UtteranceType,redUtterance,SufficientProperty,RedundantProperty,NumDistractors,NumSameDistractors,SceneVariation,speakerMessages,listenerMessages,refExp,minimal,redundant,clickedType,clickedSize,clickedColor,colorMentioned,sizeMentioned,typeMentioned,oneMentioned,theMentioned,ColorTypicality,OtherColorTypicality,OtherColor,TypicalityDiff,normTypicality,ColorTypicalityModified,ColorTypicalityUnModified,OtherColorTypicalityModified,OtherColorTypicalityUnModified,TypicalityDiffModified,normTypicalityModified,TypicalityDiffUnModified,normTypicalityUnModified) #alt1Name,alt1SpLocs,alt1LisLocs,alt2Name,alt2SpLocs,alt2LisLocs,alt3Name,alt3SpLocs,alt3LisLocs,alt4Name,alt4SpLocs,alt4LisLocs)
nrow(dd)
write_delim(dd, "../../data/englishPilot/data_exp1.tsv",delim="\t")
rm(list = ls())
library(tidyverse)
library(gridExtra)
library(brms)
library(lme4)
library(languageR)
theme_set(theme_bw(18))
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../_shared/regressionHelpers.r")
source("../_shared/createLaTeXTable.R")
# Read data
d = read_delim("../../data/EnglishPilot/data_exp1.tsv", delim = "\t")
nrow(d)
# Get color-blind friendly palette that also looks good in black and white
# #9ad0f3 -- light-blue -- 4
# #0072B2 -- dark blue -- 5
# #D55E00 -- red -- 6
cbbPalette <- c("#000000", "#009E73", "#e79f00", "#9ad0f3", "#0072B2", "#D55E00", "#CC79A7", "#F0E442")
agr = d %>%
select(redundant,RedundantProperty,NumDistractors,SceneVariation) %>%
gather(Utterance,Mentioned,-RedundantProperty,-NumDistractors,-SceneVariation) %>%
group_by(Utterance,RedundantProperty,NumDistractors,SceneVariation) %>%
summarise(Probability=mean(Mentioned),ci.low=ci.low(Mentioned),ci.high=ci.high(Mentioned)) %>%
ungroup() %>%
mutate(YMin = Probability - ci.low, YMax = Probability + ci.high, Distractors=as.factor(NumDistractors))
ggplot(agr, aes(x=SceneVariation,y=Probability,shape=Distractors,group=1)) +
geom_point() +
geom_errorbar(aes(ymin=YMin,ymax=YMax)) +
xlab("Scene variation") +
ylab("Probability of redundant modifier") +
scale_shape_discrete(name = "Number of\ndistractors") +
facet_wrap(~RedundantProperty)
ggsave(file="viz/scenevariation.pdf",width=8,height=4)
# plot by-dyad variability in overmodification strategy
agr_dyad = d %>%
select(redundant,RedundantProperty,gameid) %>%
gather(Utterance,Mentioned,-RedundantProperty,-gameid) %>%
group_by(Utterance,RedundantProperty,gameid) %>%
summarise(Probability=mean(Mentioned),ci.low=ci.low(Mentioned),ci.high=ci.high(Mentioned)) %>%
ungroup() %>%
mutate(YMin = Probability - ci.low, YMax = Probability + ci.high,dyad = fct_reorder(as.factor(gameid),Probability))
ggplot(agr_dyad, aes(x=dyad,y=Probability,color=RedundantProperty)) +
geom_point() +
geom_errorbar(aes(ymin=YMin,ymax=YMax)) +
xlab("Dyad") +
theme(axis.text.x = element_blank()) +
ylab("Probability of redundant modifier")
ggsave(file="viz/bydyad.pdf",width=8,height=4)
# plot by-dyad variability in overmodification strategy by experiment half
agr_dyad = d %>%
mutate(Half = ifelse(Trial < 37,"first","second")) %>%
select(redundant,RedundantProperty,gameid,Half) %>%
gather(Utterance,Mentioned,-RedundantProperty,-gameid,-Half) %>%
group_by(Utterance,RedundantProperty,gameid,Half) %>%
summarise(Probability=mean(Mentioned)) %>%
ungroup() %>%
select(gameid,Utterance,RedundantProperty,Half,Probability) %>%
spread(Half,Probability) %>%
mutate(Diff=second-first,dyad = fct_reorder(as.factor(gameid),Diff))
ggplot(agr_dyad, aes(x=Diff,fill=RedundantProperty)) +
geom_histogram(binwidth=.1) +
xlab("second half minus first half overmodification proportion") +
facet_wrap(~RedundantProperty)
ggsave(file="viz/bydyadhalf.pdf",width=8,height=4)
# Center predictors
d <- d %>%
mutate(SufficientProperty = factor(SufficientProperty),
redUtterance = factor(redUtterance),
gameid = factor(gameid))
centered = cbind(d,myCenter(data.frame(d %>% select(SufficientProperty, Trial, SceneVariation))))
contrasts(centered$redUtterance)
contrasts(centered$SufficientProperty)
pairscor.fnc(centered[,c("redUtterance","SufficientProperty","SceneVariation")])
# Main analysis reported in paper along with Fig. 8
m = glmer(redUtterance ~ cSufficientProperty*cSceneVariation + (1|gameid) + (1|clickedType), data=centered, family="binomial")
summary(m)
# Simple effects analysis reported in paper along with Fig. 8
m.simple = glmer(redUtterance ~ SufficientProperty*cSceneVariation - cSceneVariation + (1|gameid) + (1|clickedType), data=centered, family="binomial")
summary(m.simple)
# Main analysis reported in paper along with Fig. 8
m = glmer(redUtterance ~ cSufficientProperty*cSceneVariation + (1|gameid) + (1|clickedType), data=centered, family="binomial")
summary(m)
# Simple effects analysis reported in paper along with Fig. 8
m.simple = glmer(redUtterance ~ SufficientProperty*cSceneVariation - cSceneVariation + (1|gameid) + (1|clickedType), data=centered, family="binomial")
summary(m.simple)
# Main analysis reported in paper along with Fig. 8
m = glmer(redUtterance ~ cSufficientProperty*cSceneVariation + (1|gameid) + (1|clickedType), data=centered, family="binomial")
summary(m)
# Simple effects analysis reported in paper along with Fig. 8
m.simple = glmer(redUtterance ~ SufficientProperty*cSceneVariation - cSceneVariation + (1|gameid) + (1|clickedType), data=centered, family="binomial")
summary(m.simple)
# Supplementary analysis: do the analysis only on those cases that have scene variation > 0
centered = cbind(d %>% filter(SceneVariation > 0),myCenter(data.frame(d %>% filter(SceneVariation > 0) %>% select(SufficientProperty, Trial, SceneVariation))))
contrasts(centered$redUtterance)
contrasts(centered$SufficientProperty)
m = glmer(redUtterance ~ cSufficientProperty*cSceneVariation + (1+cSceneVariation|gameid) + (1|clickedType), data=centered, family="binomial")
summary(m) # doing the analysis only on the ratio > 0 cases gets rid of the interaction, ie variation has the same effect on color-redundant and size-redunant trials. (that is, the big scene variation slope in the color-redundant condition was driven mostly by the 0-ratio cases)
# Because of lmer's convergence issues, do the Bayesian regression, which yields the same qualitative results with maximal random effects structure
options(mc.cores = parallel::detectCores())
m.b.full = brm(redUtterance ~ cSufficientProperty*cSceneVariation + (1+cSufficientProperty*cSceneVariation|gameid) + (1+cSufficientProperty*cSceneVariation|clickedType), data=centered, family="bernoulli")
summary(m.b.full)
agr = d %>%
select(redundant,RedundantProperty,NumDistractors,SceneVariation) %>%
gather(Utterance,Mentioned,-RedundantProperty,-NumDistractors,-SceneVariation) %>%
group_by(Utterance,RedundantProperty,NumDistractors,SceneVariation) %>%
summarise(Probability=mean(Mentioned),ci.low=ci.low(Mentioned),ci.high=ci.high(Mentioned)) %>%
ungroup() %>%
mutate(YMin = Probability - ci.low, YMax = Probability + ci.high, Distractors=as.factor(NumDistractors))
ggplot(agr, aes(x=SceneVariation,y=Probability,shape=Distractors,group=1)) +
geom_point() +
geom_errorbar(aes(ymin=YMin,ymax=YMax)) +
xlab("Scene variation") +
ylab("Probability of redundant modifier") +
scale_shape_discrete(name = "Number of\ndistractors") +
facet_wrap(~RedundantProperty)
View(d %>% filter(SceneVariation == 0.5 & NumDistractors == 2)
)
View(d %>% filter(SceneVariation == 0.5 & NumDistractors == 2 & colorMentioned == FALSE)
)
)
table((d %>% filter(SceneVariation == 0.5 & NumDistractors == 2 & colorMentioned == FALSE)
+ ))
table((d %>% filter(SceneVariation == 0.5 & NumDistractors == 2 & colorMentioned == FALSE)))
View((d %>% filter(SceneVariation == 0.5 & NumDistractors == 2 & colorMentioned == FALSE)))
View(d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty) %>%
group_by(clickedType) %>%
summarize(n = n(redundant)))
d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
+ group_by(RedundantProperty) %>%
+ group_by(clickedType) %>%
+ summarize(n = n(redundant))
d$RedundantProperty
d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
+ group_by(RedundantProperty) %>%
+ group_by(clickedType) %>%
+ summarize(n = n(redundant))
d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty) %>%
group_by(clickedType) %>%
summarize(n = n(redundant))
d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty) %>%
group_by(clickedType) %>%
summarise(n = n(redundant))
d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty) %>%
group_by(clickedType) %>%
summarise(n = n())
d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(n = n())
d %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
d_2021 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
d_2021 <- d
d_2021 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
d_2020 <- read_csv("../../data/Degen2020/data_exp1.tsv")
d_2020 <- read_csv("../../data/Degen2020/data_exp1.csv")
d_2020 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
View(d_2020)
d_2020 <- read_delim("../../data/Degen2020/data_exp1.tsv", delim = "\t")
d_2020 <- read_delim("../../data/Degen2020/data_exp1.csv", delim = "\t")
d_2021 <- d
d_2021 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
d_2020 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
View(d_2020 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n()))
d_2021 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
d_2020 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
d_2020 %>% filter(SceneVariation == 0.5 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n()) %>%
filter(RedundantProperty == "color redundant")
d_2021 %>% filter(SceneVariation == 0 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
d_2020 %>% filter(SceneVariation == 0 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n()) %>%
filter(RedundantProperty == "color redundant")
d_2021 %>% filter(SceneVariation == 0 & NumDistractors == 2) %>%
group_by(RedundantProperty, clickedType) %>%
summarise(redundantRate = sum(redundant)/n())
rm(list = ls())
trials <- fromJSON("testObject.json")
library(jsonlite)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- fromJSON("testObject.json")
trials <- fromJSON("testOut.json")
View(trials)
trials <- flatten(fromJSON("testOut.json"))
View(trials)
trials <- data.frame(fromJSON("testOut.json"))
View(trials)
trials <- data.frame(fromJSON("testOut.json")) %>%
group_by(targetItem,numDistractors) %>%
summarize(n = n())
View(trials)
trials <- data.frame(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarize(n = n())
View(trials)
trials <- data.frame(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
View(trials)
trials <- data.frame(fromJSON("testOut.json"))
View(trials)
trials <- fromJSON("testOut.json")
View(trials)
trials <- rbind(fromJSON("testOut.json"))
View(trials)
trials <- bind_rows(fromJSON("testOut.json"))
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
View(trials)
library(jsonlite)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
library(jsonlite)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
View(trials)
library(jsonlite)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
View(trials)
library(jsonlite)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
library(jsonlite)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
library(jsonlite)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
trials <- bind_rows(fromJSON("testOut.json")) %>%
group_by(TargetItem,NumDistractors) %>%
summarise(n = n())
View(trials)
rm(list = ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(mongolite)
library(tidyverse)
library(jsonlite)
theme_set(theme_bw())
## for bootstrapping 95% confidence intervals
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}
prolific_summary <- read_csv("../../data/EnglishPilot/identifyingInfo/prolific_export_60afcf977007299c487304c6.csv")
prolific_ids <- (prolific_summary %>% filter(status %in% c("AWAITING REVIEW", "APPROVED")))$participant_id
rm(prolific_summary)
uname_pwd <- readLines("../../data/EnglishPilot/identifyingInfo/upwd")
con <- mongo("rounds", url = sprintf("mongodb+srv://%s@cluster0.xizoq.mongodb.net/crossling-ref", uname_pwd))
d <- data.frame(con$aggregate()) %>%
mutate(index = row_number())
d <- data.frame(con$aggregate()) %>%
mutate(index = row_number())
con$disconnect()
rm(con)
